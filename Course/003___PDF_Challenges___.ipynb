{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435d8867",
   "metadata": {},
   "source": [
    "# __PDF Challenges__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f336cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\learn\\Py\\AI_Agents\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "from modules import util as ut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9256f",
   "metadata": {},
   "source": [
    "## Pdf text problems\n",
    "\n",
    "We need to know and apply some cleaning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccea6ae",
   "metadata": {},
   "source": [
    "### Remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a014efbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample text with extra whitespaces. It should be cleaned properly.\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_whitespaces(text: str) -> str:\n",
    "    \"\"\"Remove extra whitespaces from the text.\"\"\"\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "text = '''\n",
    "This   is  a   sample   text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               with    \n",
    "        \n",
    "        \n",
    "        \n",
    "        extra   whitespaces.\n",
    "It  should  be  \n",
    "\n",
    "                cleaned \n",
    "                \n",
    "                    \n",
    "                          properly.'''\n",
    "\n",
    "cleaned_text = remove_extra_whitespaces(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b06e9",
   "metadata": {},
   "source": [
    "### Replace encoded characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482a6658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of encoded characters: - - ' ' \" \" ...\n"
     ]
    }
   ],
   "source": [
    "def replace_encoded_characters(text: str) -> str:\n",
    "    \"\"\"Replace encoded characters in the text.\"\"\"\n",
    "    replacements = {\n",
    "        '\\u2013': '-',  # en dash\n",
    "        '\\u2014': '-',  # em dash\n",
    "        '\\u2018': \"'\",  # left single quotation mark\n",
    "        '\\u2019': \"'\",  # right single quotation mark\n",
    "        '\\u201c': '\"',  # left double quotation mark\n",
    "        '\\u201d': '\"',  # right double quotation mark\n",
    "        '\\u2026': '...',  # ellipsis\n",
    "    }\n",
    "    for encoded_char, replacement in replacements.items():\n",
    "        text = text.replace(encoded_char, replacement)\n",
    "    return text\n",
    "text = \"This is an example of encoded characters: \\u2013 \\u2014 \\u2018 \\u2019 \\u201c \\u201d \\u2026\"\n",
    "cleaned_text = replace_encoded_characters(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75c163",
   "metadata": {},
   "source": [
    "# Use our own PDF processor\n",
    "from `./modules/util.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5992c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ut.SmartPdfProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862bf5b",
   "metadata": {},
   "source": [
    "### Try to load a Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2eb1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "______________________________________________________________________\n",
      "Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model\n",
      "______________________________________________________________________\n",
      "producer: PyPDF2\n",
      "creator: PyPDF\n",
      "creationdate: \n",
      "subject: Neural Information Processing Systems http://nips.cc/\n",
      "publisher: Curran Associates, Inc.\n",
      "language: en-US\n",
      "created: 2017\n",
      "eventtype: Poster\n",
      "description-abstract: The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.\n",
      "title: Attention is All you Need\n",
      "date: 2017\n",
      "moddate: 2018-02-12T21:22:10-08:00\n",
      "published: 2017\n",
      "type: Conference Proceedings\n",
      "firstpage: 5998\n",
      "book: Advances in Neural Information Processing Systems 30\n",
      "description: Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)\n",
      "editors: I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett\n",
      "author: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin\n",
      "lastpage: 6008\n",
      "source: data/pdfs/attention.pdf\n",
      "total_pages: 11\n",
      "page: 1\n",
      "page_label: 1\n",
      "chunk_method: RecursiveCharacterTextSplitter\n",
      "char_count: 2909\n"
     ]
    }
   ],
   "source": [
    "chunks = preprocessor.process_pdf(\"data/pdfs/attention.pdf\")\n",
    "print(len(chunks))  # In case there was an error, this will be 0\n",
    "\n",
    "if chunks:\n",
    "    print('_'*70)\n",
    "    print(chunks[0].page_content)\n",
    "    print('_'*70)\n",
    "    for key, value in chunks[0].metadata.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78482d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
